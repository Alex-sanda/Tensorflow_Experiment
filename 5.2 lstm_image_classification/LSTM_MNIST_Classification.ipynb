{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow.contrib.rnn as rnn\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.准备mnist数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('./data/mnist',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.构建computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#placeholder\n",
    "#超参数\n",
    "batch_size =128\n",
    "n_input = 28\n",
    "n_steps = 784//n_input#(mnist.train.images.shape[1])/n_input\n",
    "class_num = 10\n",
    "\n",
    "\n",
    "with tf.name_scope('data'):\n",
    "    X = tf.placeholder(tf.float32,shape = [batch_size,n_input*n_steps],name = \"X\")\n",
    "    Y = tf.placeholder(tf.uint8,shape = [batch_size,class_num])\n",
    "    reshaped_X = tf.reshape(X,[batch_size,n_steps,n_input],name='reshaped_X')\n",
    "    unstacked_X = tf.unstack(reshaped_X,n_steps,1,name='unstack_X')#list of tensor(batch,n_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#computation map\n",
    "hidden_unit_size = 128\n",
    "with tf.name_scope('lstm'):\n",
    "    #weight and bias for the final output of the network\n",
    "    weight = tf.Variable(tf.random_normal([hidden_unit_size,class_num]),name=\"weight_for_output\")\n",
    "    bias   = tf.Variable(tf.zeros([class_num]),name='bias_for_output')\n",
    "    \n",
    "    lstm_cell = rnn.BasicLSTMCell(hidden_unit_size,forget_bias=1.0)\n",
    "    outputs,state = rnn.static_rnn(lstm_cell,unstacked_X,dtype=tf.float32)\n",
    "    pred = tf.add(tf.matmul(outputs[-1],weight),bias,name='pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss function\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y,logits=pred),name=\"loss\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#optimizer\n",
    "learning_rate = 0.001\n",
    "with tf.name_scope('optimizer'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#evaluate\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_pred = tf.equal(tf.arg_max(pred,1),tf.arg_max(Y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Minibatch Loss= 2.156565, Training Accuracy= 0.24219\n",
      "saved at iteration:0\n",
      "Iter 1000, Minibatch Loss= 0.071404, Training Accuracy= 0.96875\n",
      "saved at iteration:1000\n",
      "Iter 2000, Minibatch Loss= 0.056611, Training Accuracy= 0.98438\n",
      "saved at iteration:2000\n",
      "Iter 3000, Minibatch Loss= 0.023989, Training Accuracy= 1.00000\n",
      "saved at iteration:3000\n",
      "Iter 4000, Minibatch Loss= 0.027956, Training Accuracy= 0.99219\n",
      "saved at iteration:4000\n",
      "Iter 5000, Minibatch Loss= 0.016840, Training Accuracy= 0.99219\n",
      "saved at iteration:5000\n",
      "Iter 6000, Minibatch Loss= 0.001119, Training Accuracy= 1.00000\n",
      "saved at iteration:6000\n",
      "Iter 7000, Minibatch Loss= 0.014666, Training Accuracy= 0.99219\n",
      "saved at iteration:7000\n",
      "Iter 8000, Minibatch Loss= 0.002093, Training Accuracy= 1.00000\n",
      "saved at iteration:8000\n",
      "Iter 9000, Minibatch Loss= 0.003177, Training Accuracy= 1.00000\n",
      "saved at iteration:9000\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "#start training\n",
    "epoch = 10000\n",
    "display_step = 1000\n",
    "save_step = 1000\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    writer = tf.summary.FileWriter('./graphs/LSTM_MNIST',sess.graph)\n",
    "    \n",
    "    \n",
    "    for i in range(epoch):\n",
    "        batch_X,batch_Y = mnist.train.next_batch(batch_size=batch_size)\n",
    "        sess.run([optimizer],feed_dict={X:batch_X,Y:batch_Y})\n",
    "        if i % display_step == 0:\n",
    "            # 计算batch上的准确率\n",
    "            acc = sess.run(accuracy, feed_dict={X: batch_X, Y: batch_Y})\n",
    "            # 计算batch上的loss\n",
    "            l = sess.run(loss, feed_dict={X: batch_X, Y: batch_Y})\n",
    "            print(\"Iter \" + str(i) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(l) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "            #保存训练结果\n",
    "            saver.save(sess,'./checkpoints/LSTM/LSTM-MNIST',global_step=i)\n",
    "            print(\"saved at iteration:{}\".format(i))\n",
    "    print(\"Optimization Finished!\")\n",
    "    writer.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/LSTM/LSTM-MNIST-9000\n",
      "accuracy for test set batch:1.0 \n"
     ]
    }
   ],
   "source": [
    "#evaluate the model on test set\n",
    "with tf.Session() as sess:\n",
    "    ckpt = tf.train.get_checkpoint_state(os.path.dirname('./checkpoints/LSTM/LSTM-MNIST'))\n",
    "    if ckpt is not None:\n",
    "        checkpoint_path = ckpt.model_checkpoint_path\n",
    "        saver.restore(sess,checkpoint_path)\n",
    "    batch_X,batch_Y = mnist.train.next_batch(batch_size)\n",
    "    feed_dict = {X:batch_X,Y:batch_Y}\n",
    "    l,acc = sess.run([loss,accuracy],feed_dict=feed_dict)\n",
    "    print(\"accuracy for test set batch:{} \".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
